{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Hybrid Search Deep Dive\n\nMaster hybrid search techniques with MongoDB `$rankFusion` and **MongoDB 8.2 Lexical Prefilters**.\n\n**What you'll learn:**\n- Vector vs keyword vs hybrid search\n- Configuring fusion weights\n- Understanding `$rankFusion` internals\n- Per-pipeline score analysis\n- **NEW: Lexical Prefilters** (fuzzy, phrase, wildcard, geo)\n- Three Filter Systems architecture\n- Search quality optimization\n\n**Prerequisites:** Completed `01_getting_started.ipynb`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from hybridrag import create_hybridrag\n",
    "\n",
    "load_dotenv()\n",
    "rag = await create_hybridrag()\n",
    "print(\"âœ“ HybridRAG initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Search Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query that benefits from different modes\n",
    "query = \"mongodb atlas vector database semantic search\"\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "\n",
    "# Vector-only: Good for semantic similarity\n",
    "vector_results = await rag.query(query=query, mode=\"vector\", top_k=3)\n",
    "print(\"VECTOR Mode (semantic similarity):\")\n",
    "for r in vector_results:\n",
    "    print(f\"  Score: {r.score:.4f} - {r.content[:60]}...\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Keyword-only: Good for exact term matching\n",
    "keyword_results = await rag.query(query=query, mode=\"keyword\", top_k=3)\n",
    "print(\"KEYWORD Mode (exact matching):\")\n",
    "for r in keyword_results:\n",
    "    print(f\"  Score: {r.score:.4f} - {r.content[:60]}...\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Hybrid: Best of both worlds\n",
    "hybrid_results = await rag.query(query=query, mode=\"hybrid\", top_k=3)\n",
    "print(\"HYBRID Mode (fusion):\")\n",
    "for r in hybrid_results:\n",
    "    print(f\"  Score: {r.score:.4f} - {r.content[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuring Fusion Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document embeddings vector similarity\"\n",
    "\n",
    "# Semantic-focused (80% vector, 20% keyword)\n",
    "semantic_focused = await rag.query(\n",
    "    query=query, mode=\"hybrid\", vector_weight=0.8, text_weight=0.2, top_k=3\n",
    ")\n",
    "\n",
    "# Keyword-focused (20% vector, 80% keyword)\n",
    "keyword_focused = await rag.query(\n",
    "    query=query, mode=\"hybrid\", vector_weight=0.2, text_weight=0.8, top_k=3\n",
    ")\n",
    "\n",
    "# Balanced (50/50)\n",
    "balanced = await rag.query(\n",
    "    query=query, mode=\"hybrid\", vector_weight=0.5, text_weight=0.5, top_k=3\n",
    ")\n",
    "\n",
    "print(\"Semantic-focused (0.8/0.2):\")\n",
    "for r in semantic_focused:\n",
    "    print(f\"  {r.score:.4f} - {r.content[:50]}...\")\n",
    "\n",
    "print(\"\\nKeyword-focused (0.2/0.8):\")\n",
    "for r in keyword_focused:\n",
    "    print(f\"  {r.score:.4f} - {r.content[:50]}...\")\n",
    "\n",
    "print(\"\\nBalanced (0.5/0.5):\")\n",
    "for r in balanced:\n",
    "    print(f\"  {r.score:.4f} - {r.content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Per-Pipeline Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query with score details\n",
    "query = \"atlas search full text\"\n",
    "\n",
    "results = await rag.query(query=query, mode=\"hybrid\", top_k=3)\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Per-Pipeline Scores:\\n\")\n",
    "\n",
    "for idx, result in enumerate(results, 1):\n",
    "    print(f\"Result {idx}: {result.content[:50]}...\")\n",
    "    print(f\"  Final Score: {result.score:.4f}\")\n",
    "\n",
    "    if hasattr(result, \"source_scores\") and result.source_scores:\n",
    "        print(f\"  Vector Score: {result.source_scores.get('vector', 'N/A')}\")\n",
    "        print(f\"  Text Score: {result.source_scores.get('text', 'N/A')}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tuning for Query Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybridrag import detect_query_type\n",
    "\n",
    "queries = [\n",
    "    \"What is MongoDB Atlas?\",  # Factual - prefer keyword\n",
    "    \"explain vector embeddings concepts\",  # Conceptual - prefer semantic\n",
    "    \"mongodb atlas vector search tutorial\",  # Mixed - balanced\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    query_type = detect_query_type(query)\n",
    "\n",
    "    # Adjust weights based on query type\n",
    "    if \"summary\" in query_type.value:\n",
    "        weights = (0.7, 0.3)  # More semantic\n",
    "    elif \"tool\" in query_type.value:\n",
    "        weights = (0.3, 0.7)  # More keyword\n",
    "    else:\n",
    "        weights = (0.5, 0.5)  # Balanced\n",
    "\n",
    "    results = await rag.query(\n",
    "        query=query,\n",
    "        mode=\"hybrid\",\n",
    "        vector_weight=weights[0],\n",
    "        text_weight=weights[1],\n",
    "        top_k=2,\n",
    "    )\n",
    "\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Type: {query_type.value}\")\n",
    "    print(f\"Weights: vector={weights[0]}, text={weights[1]}\")\n",
    "    print(f\"Top result score: {results[0].score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dynamic `numCandidates` Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HybridRAG automatically calculates numCandidates = top_k * 20\n",
    "# This ensures good recall\n",
    "\n",
    "query = \"mongodb vector search\"\n",
    "\n",
    "# Different top_k values\n",
    "for top_k in [5, 10, 20]:\n",
    "    results = await rag.query(query=query, mode=\"hybrid\", top_k=top_k)\n",
    "\n",
    "    print(f\"top_k={top_k}:\")\n",
    "    print(f\"  numCandidates={top_k * 20} (automatic)\")\n",
    "    print(f\"  Results: {len(results)}\")\n",
    "    print(f\"  Score range: {results[0].score:.4f} - {results[-1].score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Weight Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "query = \"mongodb atlas cloud database\"\n",
    "weight_configs = [(1.0, 0.0), (0.75, 0.25), (0.5, 0.5), (0.25, 0.75), (0.0, 1.0)]\n",
    "labels = [\n",
    "    \"Vector\\nOnly\",\n",
    "    \"Semantic\\nFocus\",\n",
    "    \"Balanced\",\n",
    "    \"Keyword\\nFocus\",\n",
    "    \"Keyword\\nOnly\",\n",
    "]\n",
    "\n",
    "avg_scores = []\n",
    "\n",
    "for vec_w, text_w in weight_configs:\n",
    "    mode = \"vector\" if vec_w == 1.0 else \"keyword\" if text_w == 1.0 else \"hybrid\"\n",
    "    results = await rag.query(\n",
    "        query=query, mode=mode, vector_weight=vec_w, text_weight=text_w, top_k=5\n",
    "    )\n",
    "    avg_scores.append(np.mean([r.score for r in results]))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(\n",
    "    labels, avg_scores, color=[\"#2196F3\", \"#4CAF50\", \"#FFC107\", \"#FF9800\", \"#F44336\"]\n",
    ")\n",
    "plt.ylabel(\"Average Score\")\n",
    "plt.title(f'Search Quality Across Weight Configurations\\nQuery: \"{query}\"')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Add weight labels\n",
    "for i, (vec_w, text_w) in enumerate(weight_configs):\n",
    "    plt.text(\n",
    "        i,\n",
    "        avg_scores[i] + 0.01,\n",
    "        f\"{vec_w}/{text_w}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Lexical Prefilters (MongoDB 8.2+)\n\n**NEW in MongoDB 8.2:** Apply Atlas Search operators (fuzzy, phrase, wildcard, geo) **BEFORE** vector search.\n\nThis is a game-changer for search quality:\n- `$vectorSearch` supports only MQL operators (`$eq`, `$gte`, `$in`)\n- `$search.vectorSearch` supports full Atlas Search operators **as prefilters**\n\n| Scenario | Legacy $vectorSearch | New $search.vectorSearch |\n|----------|---------------------|--------------------------|\n| \"Find docs about *machin lerning*\" | No fuzzy support | `fuzzy: {maxEdits: 2}` |\n| \"Exact phrase 'machine learning'\" | Vector similarity only | `phrase: {slop: 0}` |\n| \"Tags matching tech*\" | No wildcards | `wildcard: {query: \"tech*\"}` |\n| \"Docs within 10km of NYC\" | No geo filtering | `geoWithin` |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lexical prefilter components\n",
    "from hybridrag import (\n",
    "    LexicalPrefilterConfig,\n",
    ")\n",
    "\n",
    "# Example 1: Fuzzy matching (typo-tolerant)\n",
    "fuzzy_config = LexicalPrefilterConfig(\n",
    "    fuzzy_filters=[\n",
    "        {\n",
    "            \"path\": \"content\",\n",
    "            \"query\": \"machin lerning\",\n",
    "            \"maxEdits\": 2,\n",
    "        }  # Tolerates typos!\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Example 2: Exact phrase matching\n",
    "phrase_config = LexicalPrefilterConfig(\n",
    "    phrase_filters=[\n",
    "        {\"path\": \"content\", \"query\": \"vector database\", \"slop\": 0}  # Exact phrase\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Example 3: Wildcard pattern matching\n",
    "wildcard_config = LexicalPrefilterConfig(\n",
    "    wildcard_filters=[\n",
    "        {\"path\": \"metadata.tags\", \"query\": \"mongo*\"}  # Matches mongodb, mongoose, etc.\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Example 4: Combined filters\n",
    "combined_config = LexicalPrefilterConfig(\n",
    "    fuzzy_filters=[{\"path\": \"content\", \"query\": \"search\", \"maxEdits\": 1}],\n",
    "    range_filters={\"metadata.timestamp\": {\"gte\": \"2024-01-01\"}},\n",
    "    text_filters=[{\"path\": \"metadata.category\", \"query\": \"technology\"}],\n",
    ")\n",
    "\n",
    "print(\"Lexical Prefilter Configs Created:\")\n",
    "print(f\"  Fuzzy: {fuzzy_config}\")\n",
    "print(f\"  Phrase: {phrase_config}\")\n",
    "print(f\"  Wildcard: {wildcard_config}\")\n",
    "print(f\"  Combined: {combined_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Using Lexical Prefilters with Hybrid Search"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query with fuzzy prefiltering (typo-tolerant search)\n",
    "query = \"machine learning best practices\"\n",
    "\n",
    "# With lexical prefilter - tolerates typos in the prefilter\n",
    "filter_config = LexicalPrefilterConfig(\n",
    "    fuzzy_filters=[{\"path\": \"content\", \"query\": \"machin lerning\", \"maxEdits\": 2}],\n",
    "    range_filters={\"metadata.timestamp\": {\"gte\": \"2024-01-01\"}},\n",
    ")\n",
    "\n",
    "# HybridRAG has lexical prefilters enabled by default (MongoDB 8.2+)\n",
    "# Falls back gracefully to $vectorSearch on older MongoDB versions\n",
    "results = await rag.query(\n",
    "    query=query, mode=\"hybrid\", lexical_filter_config=filter_config, top_k=5\n",
    ")\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"Prefilters: fuzzy='machin lerning' (maxEdits=2), date>=2024-01-01\")\n",
    "print(f\"\\nResults ({len(results)} found):\")\n",
    "for idx, r in enumerate(results, 1):\n",
    "    print(f\"  {idx}. Score: {r.score:.4f} - {r.content[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### $meta Score Fields Reference (CRITICAL)\n\nDifferent MongoDB operators use different `$meta` fields for scores:\n\n| Operator | `$meta` Value | When Used |\n|----------|---------------|-----------|\n| `$vectorSearch` | `vectorSearchScore` | Legacy vector search |\n| `$search.vectorSearch` | `searchScore` | MongoDB 8.2+ with lexical prefilters |\n| `$rankFusion` | `rankFusionScore` | Hybrid search fusion |\n| `$scoreFusion` | `scoreFusionScore` | Score-based fusion |\n\nHybridRAG handles this automatically - you don't need to worry about the correct field."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the raw aggregation pipeline (for inspection)\n",
    "from hybridrag import build_search_vector_search_stage\n",
    "\n",
    "# Create a sample embedding (normally from Voyage AI)\n",
    "sample_embedding = [0.1] * 1024  # Placeholder\n",
    "\n",
    "# Build the $search.vectorSearch stage\n",
    "pipeline_stage = build_search_vector_search_stage(\n",
    "    query_vector=sample_embedding,\n",
    "    lexical_filter_config=combined_config,\n",
    "    vector_field=\"vector\",\n",
    "    index_name=\"vector_index\",\n",
    "    num_candidates=200,\n",
    "    limit=10,\n",
    ")\n",
    "\n",
    "print(\"Generated $search.vectorSearch Pipeline Stage:\")\n",
    "print(\"-\" * 50)\n",
    "import json\n",
    "\n",
    "print(json.dumps(pipeline_stage, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Best Practices\n\n### When to use each mode:\n\n**Vector-only (semantic):**\n- Conceptual questions\n- Paraphrased queries\n- Cross-lingual search\n\n**Keyword-only (exact):**\n- Technical terms\n- Product names\n- Error codes\n\n**Hybrid (recommended):**\n- Mixed queries\n- Production systems\n- When unsure\n\n### Weight configuration tips:\n\n- **Default (0.6/0.4)**: Good starting point\n- **Semantic focus (0.7-0.8/0.2-0.3)**: For conceptual queries\n- **Keyword focus (0.2-0.3/0.7-0.8)**: For exact matching\n- **Test and iterate**: Use eval metrics\n\n### Lexical Prefilters (MongoDB 8.2+):\n\n- **Fuzzy filters**: For typo-tolerant searches (`maxEdits: 1-2`)\n- **Phrase filters**: For exact multi-word matching (`slop: 0`)\n- **Wildcard filters**: For pattern matching (`*`, `?`)\n- **Geo filters**: For location-based filtering\n- **Range filters**: For date/numeric ranges\n\n### Performance:\n\n- `numCandidates`: Automatic (top_k * 20)\n- `scoreDetails: true`: Always enabled for debugging\n- Monitor per-pipeline scores for optimization\n- Lexical prefilters reduce candidate set BEFORE vectors (faster!)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Next Steps\n\n- `03_knowledge_graph_exploration.ipynb` - Graph-enhanced retrieval\n- `04_prompt_engineering.ipynb` - Optimize for answer quality\n- `05_performance_tuning.ipynb` - Production optimization\n\n### Three Filter Systems Quick Reference\n\n| Filter System | MongoDB Operator | Use Case |\n|--------------|------------------|----------|\n| `VectorSearchFilterConfig` | `$vectorSearch` | MQL operators (`$eq`, `$gte`, `$in`) |\n| `AtlasSearchFilterConfig` | `$search.compound` | Atlas Search operators (`range`, `equals`) |\n| `LexicalPrefilterConfig` | `$search.vectorSearch` | Atlas operators BEFORE vectors (fuzzy, phrase, wildcard, geo) |"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
